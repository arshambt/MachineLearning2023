{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshambt/MachineLearning2023/blob/main/Bachelor's_Final_Project/Project_GAN_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IPoD7hmbxQo"
      },
      "source": [
        "# tensorflow example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFB_4br_-msP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en5sI7yp-ya_"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh0GLL9Z_IJb",
        "outputId": "b2fd55f4-b6d4-4630-ea42-149d41e3db39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/22\n",
            "50/50 [==============================] - 119s 2s/step - d_loss: 0.5358 - g_loss: 0.7459\n",
            "Epoch 2/22\n",
            "50/50 [==============================] - 101s 2s/step - d_loss: 0.3327 - g_loss: 1.1281\n",
            "Epoch 3/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.3100 - g_loss: 1.3848\n",
            "Epoch 4/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.1240 - g_loss: 2.0308\n",
            "Epoch 5/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.0457 - g_loss: 3.3686\n",
            "Epoch 6/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.0301 - g_loss: 4.2623\n",
            "Epoch 7/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.3015 - g_loss: 2.3485\n",
            "Epoch 8/22\n",
            "50/50 [==============================] - 107s 2s/step - d_loss: 0.5703 - g_loss: 1.5432\n",
            "Epoch 9/22\n",
            "50/50 [==============================] - 103s 2s/step - d_loss: 0.5403 - g_loss: 1.1650\n",
            "Epoch 10/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.4193 - g_loss: 1.5775\n",
            "Epoch 11/22\n",
            "50/50 [==============================] - 103s 2s/step - d_loss: 0.4372 - g_loss: 1.4684\n",
            "Epoch 12/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.5284 - g_loss: 1.6716\n",
            "Epoch 13/22\n",
            "50/50 [==============================] - 108s 2s/step - d_loss: 0.5891 - g_loss: 1.2598\n",
            "Epoch 14/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.6897 - g_loss: 1.0913\n",
            "Epoch 15/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.4337 - g_loss: 1.5374\n",
            "Epoch 16/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.5512 - g_loss: 1.3923\n",
            "Epoch 17/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.5274 - g_loss: 1.3139\n",
            "Epoch 18/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.4383 - g_loss: 1.4703\n",
            "Epoch 19/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.4163 - g_loss: 1.4611\n",
            "Epoch 20/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.4120 - g_loss: 1.7397\n",
            "Epoch 21/22\n",
            "50/50 [==============================] - 105s 2s/step - d_loss: 0.3792 - g_loss: 1.8066\n",
            "Epoch 22/22\n",
            "50/50 [==============================] - 104s 2s/step - d_loss: 0.2406 - g_loss: 2.0890\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c2f06cc34c0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit the execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(50), epochs=22)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nylVObBZb6D1"
      },
      "source": [
        "# Dataset_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY8lfOgtaarp",
        "outputId": "8bffd4f7-6669-43e9-d2e5-eb4c29432f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nCvCTNUJah3X",
        "outputId": "dce3f8a6-2215-44e9-a101-b18ea560583f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkEOmJ5vakJo",
        "outputId": "3c9853e1-9cc1-4673-effa-e84304249433"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TUAn9mllcP6H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxDu11-pIP55",
        "outputId": "cc5efd62-568c-4642-96d1-c062a291803b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QWcJNsIzIWHE"
      },
      "outputs": [],
      "source": [
        "!ls gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "MBhrcVkXKGEM"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/MyDrive/Dataset_1st_1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "zN615nItY5x8"
      },
      "outputs": [],
      "source": [
        "!unzip gdrive/MyDrive/s-parameters.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaWGFPNAqZbn",
        "outputId": "f07acb7e-d95f-4fb7-d46b-7eeffb4afad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.1.0\n",
            "    Uninstalling gdown-5.1.0:\n",
            "      Successfully uninstalled gdown-5.1.0\n",
            "Successfully installed gdown-5.2.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yY9PLMJ_e2tJdAB0VYtCR1dqUyvT289n\n",
            "To: /content/img_1.png\n",
            "100% 3.62k/3.62k [00:00<00:00, 11.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/download.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = bs4.BeautifulSoup(line, features=\"html.parser\")\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1bcdQ-04EcyXGVczyHb5oFkFRX487m3lf\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 1yY9PLMJ_e2tJdAB0VYtCR1dqUyvT289n\n",
        "!gdown 1bcdQ-04EcyXGVczyHb5oFkFRX487m3lf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "p9iZdLV0pKOj",
        "outputId": "ed392982-e9ed-43a4-8fe5-b18bc72d312f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD6CAAAAACthwXhAAAD4ElEQVR4nO2dsXLUMBRFn5j8Ag2UDHTQ8Uv7UftL6ZIumZRJk+EbloLdALK1enqWpcyceyoIlq2DtbmWVpLTrVH5MLsC85A6kRszs5+zazGcWzur22luRYaTzNgNPs2uwRSSoe+61IlInQhYXeFGROpEpE7kZpezLmKjsVe8tbyLncLt8P9fj6PL11C4UZE6EakTAaur00pE6kSkTgSsrnAjInUiUicCVgeH2z7j8KuXMquOpw+9D2PUL8Pq1fH0Q+2AjoA/61InAlYHhxv5rnc9W7UJFfI9Wm4T6c7MfvQ6Y3Lm8jFXD5aLku4M3eClTkThRgSsnu7N7Hu3cCv9wzm83jqtpVzPj8vpFW731vuRplSzVDng5DyuK+AGL3UiynUiYPVB4/AZQ+a715ijvvt8dw/gBg9WV7gRkTqRWLjtMSweYVMnN6T+NmyeZrvXhjauQW7wCjcgUicCVl8Pt+6/+7zpE+291iq8FsKr6t6vu9144z/6mFCr7+r/qMKNiNSJSJ0IWF3hRkTqRKROBKy+Hm6lbvOic1iIxt5j1N4Ednf3i0v8qtPfLpT6yd3H570DCC3XBTd4qROROhFwzy09mNk3Zybk09bD89Zb581F59kXz/dgjd+vL6atR59dWotF59lfBfxZlzoRsDo43MB3PT2a2dfw9u2n/AfXqV3H3QTz67YKPFpw3tzyQs7+dLUf713HXqxIA+AGL3UiYHXlOhGpE5E6EbC6wo0IWD09mdmX1s5fvs6ttZ9dO6/7PMEFd+nJeq1z6/V1evMt0Dq3EGB1hRsRqRNpC7fFL4bgvLm82Obx+Ui+N6kv1r+F581lBbeOz7v3n/8XcoNXuAGROhGw+rb168M2S/NO0C9VfIf164P2pfFO0C/VW+vX/6JwoyJ1IlInAlZXrhOROhGpEwGrr4bbqZZ4rfvReafsR6f2Nw+ZlN/O2/0lut4pANGpAlri14TUiUidCLjnFlvn9l62xt/0HUjsrQDTlc9oiV8MqRMBq4PDjXzX51w2y+MpYTlH/V08F4AbvNSJKNyIgNX7hlvp03PIDyi9er52op6pmJ7N7HOvM3rnGh5z9WC5KOnZ0A0erK5wIyJ1IunFzD51C7fLHwphVdonzluuV66nF+v9SFPdxaBQ9Wi5TYAbvMKNiNSJgNXHDEa79329HNj7RbFrDBqHd+Zy8+5GW1C4EZE6EakTAasr3IhInYjUiUidiHKdiNSJSJ0IWD29mtnH3V8VH35XXqx89fyvttc4/NaaDpkvD27wUicidSLquRGROhGpEwGrK9yI/Om0Im99+jW7BtMAN3ipE/kNDeSSsNDH5AQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=250x250>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = cv2.imread('Dataset_1st/img_1.png')\n",
        "\n",
        "img2 = img[125:375, 125:375,0].copy()\n",
        "\n",
        "#cv2.resize(img, (30, 30))\n",
        "cv2_imshow(img[125:375, 125:375, 0])\n",
        "img3 = cv2.resize(img2, (30,30))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDXRIr0r0_GY"
      },
      "source": [
        "# 15 * 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp8-kMAI8ks9",
        "outputId": "8d3d059b-ebb3-46a5-b94a-2542170be0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15, 15)\n",
            "500\n"
          ]
        }
      ],
      "source": [
        "train_images = []\n",
        "\n",
        "for i in range (1,501):\n",
        "  img = cv2.imread(f'Dataset_1st/img_{i}.png')\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  img = img[129:251, 129:251]\n",
        "  ret, img = cv2.threshold(img, 245, 255, cv2.THRESH_BINARY)\n",
        "  img = img.astype(\"float32\") / 255.0\n",
        "  img = cv2.resize(img, (15,15))\n",
        "  #img = cv2.resize(img, (28,28))\n",
        "  #img = tf.expand_dims(img, axis=-1)\n",
        "  train_images.append(img)\n",
        "\n",
        "print(train_images[2].shape)\n",
        "print(len(train_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "a51KaB8la8lh",
        "outputId": "a2cb859e-76e0-4e75-f3a4-e9df07e9792b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b1b57605600>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "a = np.zeros((15,15,3))\n",
        "J=[]\n",
        "\n",
        "for i in range(250):\n",
        "  a = np.zeros((15,15,3))\n",
        "  a[:,:,0] = train_images[2*i]\n",
        "  a[:,:,1] = train_images[2*i+1]\n",
        "  a[:,:,2] = a[:,:,0]\n",
        "  J.append(a)\n",
        "\n",
        "J[1][:,:,0]\n",
        "plt.imshow(J[3][:,:,2], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQcMg2Y1P_M"
      },
      "source": [
        "# PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "kH06hzuh6tI8",
        "outputId": "06fa0e11-316e-45ad-c2bc-045a90926103"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAGFCAYAAAA2OmCIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANpUlEQVR4nO3dTXLiyBoF0LTjRUdPgDlhVtD7X0fPegOOYAHSoGboDTrsV90FjwT9cFM6Z1jholTowiXR59TbMAxDAQCivL/6AACAXyloAAikoAEgkIIGgEAKGgACKWgACKSgASDQf2p+6HK5lPP5XHa7XXl7e5v7mFZnGIbS9305Ho/l/b3Nz0QyMJ4cIAOUUp+DqoI+n8/ldDpNdnBb9fn5WT4+Pl59GE+RgenIATJAKfdzUFXQu93u+8H2+/00R7YhXdeV0+n0/Ty2SAbGkwNkgFLqc1BV0F9fY+z3eydkhJa/DpKB6cgBMkAp93PQ5kUQAFg5BQ0Agaq+4oZHLfkVnhuy8Sj5bEfq5YBr5/XWsT6bAStoAAikoAEgkIIGgEAKGgACKWgACLT5Ke5HJgRNY/5q6qlFtutalubKkXy2Y+y5avk9ygoaAAIpaAAIpKABIJCCBoBAmx8SA3LZkpMts4IGgEAKGgACKWgACKSgASCQggaAQKa4gdmYwobnWUEDQCAFDQCBFDQABFLQABDIkNgDlrxfLe1bckAq1bXXh3uwr1PL911OZQUNAIEUNAAEUtAAEEhBA0CgTQ2JzTG0YzACINeS78VT/1tW0AAQSEEDQCAFDQCBFDQABFLQABBoU1PcYyfsbPX5qzX8/53XDJ5z+CcraAAIpKABIJCCBoBAChoAAm1qSGxJ7gX8WmOff/cshmnM8V64ldecFTQABFLQABBIQQNAIAUNAIEUNAAEamaK+9Yk4Fam+ZjGtbyM3erTxL7XJ7fJwPOsoAEgkIIGgEAKGgACKWgACDTLkNhah2YMO2R6JG+1PzvF0NO/f7brunI4HKr//lq19Doy/MYrWUEDQCAFDQCBFDQABFLQABComZ3E4Jba3cEe+VlDQNszx7AhjGEFDQCBFDQABFLQABBIQQNAIAUNAIFmmeIeOwG75DSlaV1kgFLG/zZAjTVv9+p1ND0raAAIpKABIJCCBoBAChoAAkVu9bnEsMbcfj6uNQ+GpLqVC1s0wjyWfG2lvu9PzQoaAAIpaAAIpKABIJCCBoBAChoAAkVOcV/zyNSeacL2OYdt8RwiA9OzggaAQAoaAAIpaAAIVHUN+uvaQtd1sx5Mi2qek6+fafkazZozsNT/SQ7W49n/vwxQSn0Oqgq67/tSSimn02nkYa3PI1t49n3f7Jafa87A0udEDto39vzJAKXcz8HbUPFR7nK5lPP5XHa7nb2MnzAMQ+n7vhyPx/L+3uZVBRkYTw6QAUqpz0FVQQMAy2rzIxwArJyCBoBAChoAAiloAAikoAEgkIIGgEAKGgACKWgACKSgASCQggaAQAoaAAIpaAAIVHW7SXcvGccdbChFDpAB/labg6qCPp/P7v05gc/Pz/Lx8fHqw3iKDExHDpABSrmfg6qC3u123w+23++nObIN6bqunE6n7+exRTIwnhwgA5RSn4Oqgv76GmO/3zshI7T8dZAMTEcOkAFKuZ+DNi+CAMDKVa2gAVLcWnUMw7DwkbCEJb9tSMuQFTQABFLQABBIQQNAIAUNAIEUNAAEMsXNYkzfAo+69v6wlfcSK2gACKSgASCQggaAQAoaAAKtckhsy1vDpXjkHIw9X84BMIW0m5hYQQNAIAUNAIEUNAAEUtAAEEhBA0CgVU5xm+p9vS1vzwe0aan3oq7ryuFwuPtzVtAAEEhBA0AgBQ0AgRQ0AARa5ZDYkgw+AWS8F65tm2craAAIpKABIJCCBoBAChoAAhkSA0ZLGM65dgyGNV8vIRutsoIGgEAKGgACKWgACKSgASCQggaAQKuc4l5yapB6a5uw5H9St3Mc+14gs+ONfQ63PJ1vBQ0AgRQ0AARS0AAQSEEDQKDFhsTmulfoq7eRM5AGy7LVJ1thBQ0AgRQ0AARS0AAQSEEDQCAFDQCBVrnV5y0mOoG5zPWbKmyXFTQABFLQABBIQQNAIAUNAIE2NSR2zVxbddoCFNiSR4bhDNTVsYIGgEAKGgACKWgACKSgASDQ5ofErpl6UKHrunI4HCZ9TOCfDBixNlbQABBIQQNAIAUNAIEUNAAEUtAAEGiVU9ymOQHWYcvv51bQABBIQQNAIAUNAIEUNAAEWmxIbIp7hS7194F18x5BC6ygASCQggaAQAoaAAIpaAAIpKABIFDkVp9Lbu1mmhO2Z8vbR9IOK2gACKSgASCQggaAQFXXoL+u13RdN+vBpJj6//n1eC1f99paBuYgB8jA/7eVXNXmoKqg+74vpZRyOp1GHlYbDofDLI/b9/1sjz23rWVgTnKADFzX6nPyrHs5eBsqPspdLpdyPp/Lbrcz9fyEYRhK3/fleDyW9/c2ryrIwHhygAxQSn0OqgoaAFhWmx/hAGDlFDQABFLQABBIQQNAIAUNAIEUNAAEUtAAEEhBA0AgBQ0AgRQ0AARS0AAQSEEDQKCq2026e8k47mBDKXKADPC32hxUFfT5fHb/1wl8fn6Wj4+PVx/GU2RgOnKADFDK/RxUFfRut/t+sP1+P82RbUjXdeV0On0/jy2SgfHkABmglPocVBX019cY+/3eCRmh5a+DZGA6coAMUMr9HLR5EQQAVk5BA0Cgqq+4AeZ27eu+YRhecCS0am0ZsoIGgEAKGgACKWgACKSgASCQggaAQKa4gab88ccfi/1bv/3229U///PPPxc7Btr37MY0VtAAEEhBA0AgBQ0AgRQ0AAQyJAY05a+//nr1IbACLWwLagUNAIEUNAAEUtAAEEhBA0AgBQ0AgUxxA7N5dovDZ/5+2gQujGUFDQCBFDQABFLQABBIQQNAoGaGxG4NixgM4Zqxw0mPkMHbHnluxm69uOQ5v0YOmJoVNAAEUtAAEEhBA0AgBQ0AgSKHxB4Z9hg7GGKwY52c11xzDXM556wtA1bQABBIQQNAIAUNAIEUNAAEUtAAEChyivvaJJ6tPmHdal/3XvOZbK9727+Pt+u6cjgc7v49K2gACKSgASCQggaAQAoaAAJFDomB4SDW4tX3qV5Ka6/PFo7XChoAAiloAAikoAEgkIIGgEAKGgACmeIGYFFr3RZ06i2praABIJCCBoBAChoAAiloAAjUzJBYC9uy/Wwr2/sBPKq19/NXsYIGgEAKGgACKWgACKSgASBQM0NiwDr8/vvvrz4EaIIVNAAEUtAAEEhBA0AgBQ0AgRQ0AAQyxQ0s6sePH68+BGiCFTQABFLQABBIQQNAIAUNAIEMiRHJ/WIpRQ6Yz9vb26sP4S4raAAIpKABIJCCBoBAChoAAiloAAi0+SnuFib5gOckvL5/nkTvuq4cDocXHs3yljwHj0z9t/AbAlbQABBIQQNAIAUNAIGqrkF/fVffdd2sB7N2LVzzuEUGxvt67uRgW35+rmRgXonHdE1tDqoKuu/7Ukopp9Np5GFtW9/3zQ6IyMB05GBbrp1rGZhHa8/pvRy8DRUf5S6XSzmfz2W320VMRbZmGIbS9305Ho/l/b3NqwoyMJ4cIAOUUp+DqoIGAJbV5kc4AFg5BQ0AgRQ0AARS0AAQSEEDQCAFDQCBFDQABFLQABBIQQNAIAUNAIEUNAAEUtAAEKjqdpPuXjKOO9hQihwgA/ytNgdVBX0+nyPv/dmaz8/P8vHx8erDeIoMTEcOkAFKuZ+DqoLe7XbfD7bf76c5sg3puq6cTqfv57FFMjCeHCADlFKfg6qC/voaY7/fOyEjtPx1kAxMRw6QAUq5n4M2L4IAwMpVraDhUdc+GQ7D8IIjAWiTFTQABFLQABBIQQNAIAUNAIEUNAAEWmyK+9bve12b7F3ydwRNFo/zyLkae16dK+bkNw8ybbkPrKABIJCCBoBAChoAAiloAAg0y5CYwaHtuPX8G7gBbtny4NcjrKABIJCCBoBAChoAAiloAAikoAEg0CxT3I9s39nyhB255A3aM/b1ueR0+BKsoAEgkIIGgEAKGgACKWgACPTyrT4hkSGzXKnvLzJzXer5aoEVNAAEUtAAEEhBA0AgBQ0AgWYZEoOtD8YwjSXvK26YiTRW0AAQSEEDQCAFDQCBFDQABFLQABBosSluU72kMr1LKd6jEszxWhz7mK/MhRU0AARS0AAQSEEDQCAFDQCBbPXJyxnSYs3k+1dLbtd669+qPS9TnL9n/79W0AAQSEEDQCAFDQCBFDQABFLQABDIFDcvZ4tFYC63prBbeN+xggaAQAoaAAIpaAAIpKABINAsQ2ItXHxnPWylmGvJ+/u++n1n7JaSa/Xq89IyK2gACKSgASCQggaAQAoaAALZSYxIrx6sMdgyDc8jS7qWt1e/l4xhBQ0AgRQ0AARS0AAQSEEDQCAFDQCBTHETyfQvsHVW0AAQSEEDQCAFDQCBFDQABDIkBsRacpvGuQYTf37cruvK4XCY5d9hfaygASCQggaAQAoaAAIpaAAIpKABIJApbiDW2MnqR6bAx06M2542U8vnxQoaAAIpaAAIpKABIFDVNeiv7/C7rpv1YNbq63lr+VqIDIwnB+tW85zIAKXU56CqoPu+L6WUcjqdRh7WtvV93+w2fzIwHTlYp0fOqQxQyv0cvA0VH+Uul0s5n89lt9stujfuWgzDUPq+L8fjsby/t3lVQQbGkwNkgFLqc1BV0ADAstr8CAcAK6egASCQggaAQAoaAAIpaAAIpKABIJCCBoBA/wW/Qav6SI8urgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x480 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(train_images[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qng_yVqsT4cs",
        "outputId": "29c2fcc7-d052-4153-a025-5e8171066247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 15, 15)\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.shuffle(50)\n",
        "j=[]\n",
        "for element in dataset:\n",
        "  j.append(element)\n",
        "\n",
        "print(j[10].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzDVoWlr7uRX",
        "outputId": "207b8386-934f-4bf3-f11b-82d58fe611cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "4\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "for n, real_samples in enumerate(dataset):\n",
        "  i = real_samples.shape\n",
        "\n",
        "  print(i[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMDPIQhYZWZn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "tr_m = []\n",
        "tr_ph = []\n",
        "\n",
        "for i in range(6):\n",
        "  with open(f's-parameters/test_{i+1}_1.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "    tr_m.append(text)\n",
        "  with open(f's-parameters/test_{i+1}_2.txt', 'r') as f2:\n",
        "    text2 = f2.read()\n",
        "    tr_ph.append(text2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSUnHf8Riuu9",
        "outputId": "849de70d-850d-46b6-e62c-d296167f862b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       -2.660353\n",
            "1       -2.623166\n",
            "2       -2.585975\n",
            "3       -2.548785\n",
            "4       -2.511600\n",
            "          ...    \n",
            "1999   -95.261803\n",
            "2000   -95.304302\n",
            "2001   -95.346925\n",
            "2002   -95.389675\n",
            "2003   -95.432553\n",
            "Name: 1, Length: 2004, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "tr = []\n",
        "\n",
        "for i in range(6):\n",
        "  df_m = pd.read_csv(f's-parameters/test_{i+1}_1.txt', sep='\\s+', header=None, index_col=False)\n",
        "  df_ph = pd.read_csv(f's-parameters/test_{i+1}_2.txt', sep='\\s+', header=None, index_col=False)\n",
        "  df = pd.concat([df_m,df_ph], axis=0, ignore_index=True)\n",
        "  df = df.drop(0, axis=0)\n",
        "  df = df.drop(1, axis=0)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  v = pd.to_numeric(df[1], errors = 'coerce')\n",
        "\n",
        "  tr.append(v)\n",
        "\n",
        "print(v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxYPlt2OXzFT",
        "outputId": "0f595a99-d9ea-473a-ff05-27a694166724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ -0.42029576  -0.44471994  -0.46979037 ... -97.042198   -97.08975\n",
            " -97.137515  ], shape=(2004,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ -9.5324251  -9.5687162  -9.6048777 ... -95.418545  -94.987812\n",
            " -94.512067 ], shape=(2004,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ -9.0412828  -9.014697   -8.9880174 ... -85.075884  -85.117092\n",
            " -85.158301 ], shape=(2004,), dtype=float64)\n",
            "tf.Tensor([-13.382558 -13.414224 -13.445791 ... -42.416388 -47.994139 -52.83704 ], shape=(2004,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ -4.1590062  -4.1498337  -4.1404861 ... -86.375132  -86.400552\n",
            " -86.425939 ], shape=(2004,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ -2.6603532  -2.6231657  -2.585975  ... -95.346925  -95.389675\n",
            " -95.432553 ], shape=(2004,), dtype=float64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr_ds = tf.data.Dataset.from_tensor_slices(tr)\n",
        "\n",
        "\n",
        "l = []\n",
        "for element in tr_ds:\n",
        "  print(element)\n",
        "  l.append(element)\n",
        "\n",
        "len(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGHHqNTrhCWd",
        "outputId": "ebe6923d-82c2-4075-b53f-eb2d162205db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(42,), dtype=float64, numpy=\n",
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 100.,\n",
              "       107., 114., 121., 135., 142., 149., 156., 163., 170., 177., 184.,\n",
              "       191., 198., 205., 212., 219., 226., 233., 240., 247.])>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_m = pd.read_csv('/content/Dt_1.txt', sep='\\s+', header=None)\n",
        "df_ph = pd.read_csv('/content/DT_2.txt', sep='\\s+', header=None)\n",
        "\n",
        "df = pd.concat([df_m, df_ph], axis=0, ignore_index=True)\n",
        "\n",
        "d_tr = df.iloc[:,1]\n",
        "\n",
        "d_tr = d_tr.astype(float)\n",
        "\n",
        "tr_t = tf.convert_to_tensor(d_tr)\n",
        "tr_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9oYYtcpiWYA"
      },
      "source": [
        "# Model_1: Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNlsA4rYrcqk",
        "outputId": "6e4fade1-77cb-4570-b986-53ccb20ce272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckdJjf4fx-2H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import optuna\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization\n",
        "\n",
        "# Discriminator model\n",
        "d_model = Sequential()\n",
        "d_model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"valid\"))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"valid\"))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Flatten())\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "g_model = Sequential()\n",
        "g_model.add(Dense(7*7*128, input_dim=128))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "g_model.add(Reshape((7,7,128)))\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2D(1, (4,4), activation='sigmoid', padding='same'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvfWQDog8lf5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import optuna\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization\n",
        "\n",
        "# Create the discriminator\n",
        "def objective(trial):\n",
        "  d_model = Sequential()\n",
        "  #n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "  #for i in range(n_layers):\n",
        "  d_model.add(Conv2D(filters= trial.suggest_categorical('filters', [32,64]),\n",
        "                     kernel_size= trial.suggest_categorical('kernel_size', [3,5]),\n",
        "                     strides= trial.suggest_categorical('strides', [1,2]),\n",
        "                     padding='valid', input_shape=(15,15,1)))\n",
        "  d_model.add(LeakyReLU(alpha=0.2))\n",
        "  d_model.add(Conv2D(filters= trial.suggest_categorical('filters', [32,64]),\n",
        "                     kernel_size= trial.suggest_categorical('kernel_size', [3,5]),\n",
        "                     strides= trial.suggest_categorical('strides', [1,2]),\n",
        "                     padding='valid'))\n",
        "  d_model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  d_model.add(Flatten())\n",
        "  d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return d_model\n",
        "\n",
        "def objective(trial):\n",
        "  g_model = Sequential()\n",
        "  #model.add(Input(shape=(128,)))\n",
        "  g_model.add(Dense(7*7*128, input_dim=128))\n",
        "  g_model.add(LeakyReLU(alpha=0.2))\n",
        "  g_model.add(Reshape((7,7,128)))\n",
        "  g_model.add(Conv2DTranspose(filters= trial.suggest_categorical('filters', [64,128]),\n",
        "                     kernel_size= trial.suggest_categorical('kernel_size', [3,5]),\n",
        "                     strides= trial.suggest_categorical('strides', [1,2]),\n",
        "                     padding='valid'))\n",
        "  g_model.add(LeakyReLU(alpha=0.2))\n",
        "  g_model.add(Conv2DTranspose(filters= trial.suggest_categorical('filters', [64,128]),\n",
        "                     kernel_size= trial.suggest_categorical('kernel_size', [3,5]),\n",
        "                     strides= trial.suggest_categorical('strides', [1,2]),\n",
        "                     padding='valid'))\n",
        "  g_model.add(LeakyReLU(alpha=0.2))\n",
        "  g_model.add(Conv2DTranspose(filters= trial.suggest_categorical('filters', [64,128]),\n",
        "                     kernel_size= trial.suggest_categorical('kernel_size', [3,5]),\n",
        "                     strides= trial.suggest_categorical('strides', [1,2]),\n",
        "                     padding='valid'))\n",
        "  g_model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  g_model.add(Conv2D(1, (4,4), activation='sigmoid', padding='same'))\n",
        "\n",
        "  return g_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "qvYkC3ktq7m8",
        "outputId": "d0a593a0-9b01-4eaa-c143-1d720d2b9c54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-25 14:35:38,733] A new study created in memory with name: no-name-42f3b8b1-8d4d-4fec-8ac5-ab06312fd1e9\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'objective' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e5765535ee57>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'objective' is not defined"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oewo3krpxHDS"
      },
      "source": [
        "# Model_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A9w9OcHeM_b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "def thresholded_sigmoid(x, threshold=0.5):\n",
        "    return tf.sigmoid(x - threshold)\n",
        "\n",
        "# Create a custom layer with the thresholded sigmoid activation\n",
        "class ThresholdedSigmoid(Activation):\n",
        "    def __init__(self, threshold=0.5, **kwargs):\n",
        "        super(ThresholdedSigmoid, self).__init__(lambda x: thresholded_sigmoid(x, threshold), **kwargs)\n",
        "        self.threshold = threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv_Z3n9DxJ_J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization\n",
        "\n",
        "# Discriminator model\n",
        "d_model = Sequential()\n",
        "d_model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"valid\", input_shape=(15,15,1)))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"valid\"))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Flatten())\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "g_model = Sequential()\n",
        "g_model.add(Dense(7*7*128, input_dim=128))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "g_model.add(Reshape((7,7,128)))\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "g_model.add(Conv2D(64, kernel_size=(4,4), strides=(1,1), padding='same'))\n",
        "\n",
        "g_model.add(Conv2D(1, (4,4), activation=ThresholdedSigmoid(threshold=0.5), padding='same'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hncXtT3aKe5"
      },
      "source": [
        "# Model Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLIBwPVSaJcR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization, Activation\n",
        "\n",
        "# Discriminator model\n",
        "d_model = Sequential()\n",
        "d_model.add(Conv2D(64, (4, 4), strides=(2, 2), padding=\"valid\", input_shape=(15,15,1)))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "#d_model.add(Dropout(0.4))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(64, (4, 4), strides=(2, 2), padding=\"valid\"))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "#d_model.add(Dropout(0.4))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "d_model.add(Flatten())\n",
        "d_model.add(Dropout(0.4))\n",
        "#d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "g_model = Sequential()\n",
        "g_model.add(Dense(7*7*128, input_dim=128))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "g_model.add(Reshape((7,7,128)))\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "#g_model.add(Conv2D(64, kernel_size=(4,4), strides=(1,1), padding='same'))\n",
        "\n",
        "#g_model.add(Conv2D(64, kernel_size=(4,4), strides=(1,1), padding='same'))\n",
        "\n",
        "g_model.add(Conv2D(1, (4,4), activation='sigmoid', padding='same'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J8I6Hl-ifvq"
      },
      "source": [
        "# Model_2: Youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN4RLhPYaOtL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, UpSampling2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization\n",
        "\n",
        "\n",
        "def Discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, 5, input_shape=(15,15,1)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(64, 5))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #model.add(Conv2D(128, 5))\n",
        "  #model.add(LeakyReLU(alpha=0.2))\n",
        "  #model.add(Dropout(0.4))\n",
        "\n",
        "  #model.add(Conv2D(256, 5))\n",
        "  #model.add(LeakyReLU(alpha=0.2))\n",
        "  #model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model\n",
        "\n",
        "def Generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(7*7*128, input_dim=128))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, 5, padding='valid'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, 4, padding='valid'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, 3, padding='valid'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, 4, padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, 4, padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(1, 4, activation='sigmoid', padding='same'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gebmztzxiuzI"
      },
      "source": [
        "# Model_3: Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IgXWXBviq-x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization\n",
        "\n",
        "\n",
        "# Discriminator model\n",
        "\n",
        "d_model = Sequential()\n",
        "d_model.add(Conv2D(64, kernel_size= (3,3), strides=(1,1), padding='valid', input_shape=(15,15,1)))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Conv2D(512, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "d_model.add(LeakyReLU(alpha=0.2))\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "d_model.add(Flatten())\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Generator model\n",
        "\n",
        "g_model = Sequential()\n",
        "\n",
        "g_model.add(Dense(7*7*128, input_dim=128))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "g_model.add(Reshape((7,7,128)))\n",
        "g_model.add(Conv2DTranspose(256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "g_model.add(Conv2DTranspose(64, kernel_size=(4,4), strides=(1,1), padding='valid'))\n",
        "g_model.add(LeakyReLU(alpha=0.2))\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "g_model.add(Conv2D(1, (4,4), activation='sigmoid', padding='same'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYhcnnzCi4RV"
      },
      "source": [
        "# Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "dOjR_SOFtp6h",
        "outputId": "f32aa262-0366-4c0b-a305-8c84382c2c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0. 100. 107. 114. 121. 135. 142. 149.\n",
            "  156. 163. 170. 177. 184. 191. 198. 205. 212. 219. 226. 233. 240. 247.]], shape=(1, 42), dtype=float32)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128), found shape=(1, 170)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-38d8ad6a1d84>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_latent_vectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgenerated_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128), found shape=(1, 170)"
          ]
        }
      ],
      "source": [
        "random_latent_vectors = tf.random.normal(shape=(1, 128))\n",
        "\n",
        "tr_t = tf.expand_dims(d_tr, axis=-1)\n",
        "tr_t = tf.reshape(tr_t, (1,tr_t.shape[0]))\n",
        "tr_t = tf.cast(tr_t, tf.float32)\n",
        "\n",
        "print(tr_t)\n",
        "input = tf.concat([tr_t, random_latent_vectors], axis=1)\n",
        "input\n",
        "generated_samples = g_model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G6VweoYhiRTx",
        "outputId": "5621fb3e-010a-4b26-fe3d-1ffb5e22c8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_69 (Conv2D)          (None, 8, 8, 32)          320       \n",
            "                                                                 \n",
            " leaky_re_lu_131 (LeakyReLU  (None, 8, 8, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 4, 4, 64)          18496     \n",
            "                                                                 \n",
            " batch_normalization_116 (B  (None, 4, 4, 64)          256       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " leaky_re_lu_132 (LeakyReLU  (None, 4, 4, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 2, 2, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_117 (B  (None, 2, 2, 128)         512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " leaky_re_lu_133 (LeakyReLU  (None, 2, 2, 128)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93953 (367.00 KB)\n",
            "Trainable params: 93569 (365.50 KB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "d_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ztnk3xumTwh2",
        "outputId": "395ec1ce-300b-45c6-978e-ad8f5f1685a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 12544)             1266944   \n",
            "                                                                 \n",
            " reshape_22 (Reshape)        (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_69 (Conv2  (None, 15, 15, 128)       295040    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_122 (B  (None, 15, 15, 128)       512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " leaky_re_lu_139 (LeakyReLU  (None, 15, 15, 128)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_transpose_70 (Conv2  (None, 15, 15, 64)        73792     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_123 (B  (None, 15, 15, 64)        256       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " leaky_re_lu_140 (LeakyReLU  (None, 15, 15, 64)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_transpose_71 (Conv2  (None, 15, 15, 1)         577       \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 15, 15, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1637121 (6.25 MB)\n",
            "Trainable params: 1636737 (6.24 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "g_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0yUp_2TsNXF",
        "outputId": "fc27397a-6855-4f91-d895-67b1963c2b0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 15, 1), dtype=float32, numpy=\n",
              "array([[[1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.]],\n",
              "\n",
              "       [[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.]],\n",
              "\n",
              "       [[1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.]]], dtype=float32)>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_latent_vectors = tf.random.normal((16, 128,1))\n",
        "generated_samples = g_model(random_latent_vectors, training=False)\n",
        "generated_samples = generated_samples.numpy()\n",
        "\n",
        "for z in range(generated_samples.shape[0]):\n",
        "  for i in range(generated_samples.shape[1]):\n",
        "    for j in range(generated_samples.shape[2]):\n",
        "      if generated_samples[z,i,j] >= 0.5:\n",
        "        generated_samples[z,i,j] = 1\n",
        "      else:\n",
        "        generated_samples[z,i,j] = 0\n",
        "\n",
        "generated_samples = tf.convert_to_tensor(generated_samples)\n",
        "generated_samples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn4rvXlQY80z",
        "outputId": "13c7f1c6-2e40-4ac1-c460-59405e861f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 15, 1), dtype=float32, numpy=\n",
              "array([[[0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586]],\n",
              "\n",
              "       [[0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.7310586],\n",
              "        [0.5      ],\n",
              "        [0.7310586],\n",
              "        [0.7310586]]], dtype=float32)>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_latent_vectors = tf.random.normal((16, 128,1))\n",
        "generated_samples = g_model(random_latent_vectors, training=False)\n",
        "\n",
        "threshold = 0.5\n",
        "generated_samples = tf.where(generated_samples >= threshold, tf.ones_like(generated_samples), tf.zeros_like(generated_samples))\n",
        "generated_samples = tf.sigmoid(generated_samples, threshold)\n",
        "generated_samples[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zXVc8WxR-YBw",
        "outputId": "fc27db0e-2d17-469f-cb43-80338e39d495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bb27b3ed600>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#random_latent_vectors = tf.random.normal((16, 128,1))\n",
        "#generated_samples = g_model(random_latent_vectors, training=False)\n",
        "plt.imshow(generated_samples[0], cmap=\"gray\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc4y7URUeh7J"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XBB9DH1en_w"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "g_opt = Adam(learning_rate=0.0003)\n",
        "d_opt = Adam(learning_rate=0.00003)\n",
        "\n",
        "loss_function = BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IPs5ZUeaPmm",
        "outputId": "ee7e00af-8dc2-4208-df8b-4ec1102fe3b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.metrics.accuracy_metrics.BinaryAccuracy at 0x7b15b66cd960>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "et1PbllQ8tZh",
        "outputId": "ad071d89-edc4-4867-ab0b-c738418be5e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n        # Update metrics and return their value.\\n      self.d_loss_tracker.update_state(d_loss)\\n      self.g_loss_tracker.update_state(g_loss)\\n      return {\\n            \"d_loss\": self.d_loss_tracker.result(),\\n            \"g_loss\": self.g_loss_tracker.result(),\\n        }\\n'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class GAN(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "      threshold = 0.5\n",
        "      batch_size = tf.shape(real_images)[0]\n",
        "      random_latent_vectors = tf.random.normal((batch_size, self.latent_dim,1))\n",
        "\n",
        "        # Decode them to fake images\n",
        "      generated_samples = self.generator(random_latent_vectors, training=False)\n",
        "\n",
        "\n",
        "      with tf.GradientTape() as d_tape:\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_samples, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "\n",
        "        # Add random noise to the labels - important trick!\n",
        "        #labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "        noise_real = -0.15*tf.random.uniform((batch_size,1))\n",
        "        noise_fake = 0.15*tf.random.uniform((batch_size,1))\n",
        "\n",
        "        labels += tf.concat([noise_fake, noise_real], axis=0)\n",
        "\n",
        "        # Train the discriminator\n",
        "        #with tf.GradientTape() as tape:\n",
        "        predictions = self.discriminator(combined_images, training=True)\n",
        "        d_loss = self.loss_fn(labels, predictions)\n",
        "      grads = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "      self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
        "\n",
        "      with tf.GradientTape() as g_tape:\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal((batch_size, self.latent_dim,1))\n",
        "        generated_samples = self.generator(random_latent_vectors, training=True)\n",
        "\n",
        "\n",
        "        ## THRESHOLD FOR GENERATOR'S OUTPUT ##\n",
        "      #generated_samples = tf.cast(tf.math.greater_equal(generated_samples, threshold), dtype=tf.float32)\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        #with tf.GradientTape() as tape:\n",
        "        predictions = self.discriminator(generated_samples, training= False)\n",
        "        g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "      grads = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "      self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "      self.d_loss_tracker.update_state(d_loss)\n",
        "      self.g_loss_tracker.update_state(g_loss)\n",
        "      return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLiVxcAXfCBK"
      },
      "outputs": [],
      "source": [
        "class GAN(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "      threshold = 0.5\n",
        "      batch_size = tf.shape(real_images)[0]\n",
        "      random_latent_vectors = tf.random.normal((batch_size, self.latent_dim,1))\n",
        "\n",
        "        # Decode them to fake images\n",
        "      generated_samples = self.generator(random_latent_vectors, training=False)\n",
        "      generated_samples = tf.where(generated_samples >= threshold, tf.ones_like(generated_samples), tf.zeros_like(generated_samples))\n",
        "\n",
        "      with tf.GradientTape() as d_tape:\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_samples, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "\n",
        "        # Add random noise to the labels - important trick!\n",
        "        #labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "        noise_real = -0.15*tf.random.uniform((batch_size,1))\n",
        "        noise_fake = 0.15*tf.random.uniform((batch_size,1))\n",
        "\n",
        "        labels += tf.concat([noise_fake, noise_real], axis=0)\n",
        "\n",
        "        # Train the discriminator\n",
        "        #with tf.GradientTape() as tape:\n",
        "        predictions = self.discriminator(combined_images, training=True)\n",
        "        d_loss = self.loss_fn(labels, predictions)\n",
        "      grads = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "      self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
        "\n",
        "      with tf.GradientTape() as g_tape:\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal((batch_size, self.latent_dim,1))\n",
        "        generated_samples = self.generator(random_latent_vectors, training=True)\n",
        "\n",
        "\n",
        "        ## THRESHOLD FOR GENERATOR'S OUTPUT ##\n",
        "        #generated_samples = tf.where(generated_samples >= threshold, tf.ones_like(generated_samples), tf.zeros_like(generated_samples))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        #with tf.GradientTape() as tape:\n",
        "        predictions = self.discriminator(generated_samples, training= False)\n",
        "        g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "      grads = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "      self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "      self.d_loss_tracker.update_state(d_loss)\n",
        "      self.g_loss_tracker.update_state(g_loss)\n",
        "      return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "vYGJJWtJ-4nu",
        "outputId": "d917c2ac-9393-4e03-ee95-4b7742ee566d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-77-718850b9fc8d>, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-77-718850b9fc8d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    random_latent_vectors = tf.random.normal((16, 128,1))l\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  random_latent_vectors = tf.random.normal((16, 128,1))\n",
        "  generated_samples = g_model(random_latent_vectors, training=False)\n",
        "\n",
        "        ## THRESHOLD FOR GENERATOR'S OUTPUT ##\n",
        "  #generated_samples = tf.where(generated_samples >= threshold, tf.ones_like(generated_samples), tf.zeros_like(generated_samples))\n",
        "\n",
        "  misleading_labels = tf.zeros((16, 1))\n",
        "\n",
        "  predictions = d_model(generated_samples, training= False)\n",
        "\n",
        "  g_loss = loss_function(misleading_labels, predictions)\n",
        "grads = tape.gradient(g_loss, g_model.trainable_variables)\n",
        "g_opt.apply_gradients(zip(grads, g_model.trainable_variables))\n",
        "\n",
        "print(g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtaIpvpolnL0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "\n",
        "class ModelMonitor(Callback):\n",
        "  def __init__(self, num_img=2, latent_dim=128):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    random_latent_vectors = tf.random.normal((self.num_img, self.latent_dim,1))\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    for i in range(1):\n",
        "      img = array_to_img(generated_images[i])\n",
        "      img.save(os.path.join('GAN_img', f'generated_image_{epoch}_{i}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NahVtNCOTFbF",
        "outputId": "a2823357-5315-42a6-ab1e-a36cc596ff95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "32/32 [==============================] - 4s 33ms/step - d_loss: 0.6977 - g_loss: 0.6887\n",
            "Epoch 2/300\n",
            "32/32 [==============================] - 1s 30ms/step - d_loss: 0.7013 - g_loss: 0.6845\n",
            "Epoch 3/300\n",
            "32/32 [==============================] - 1s 29ms/step - d_loss: 0.6954 - g_loss: 0.6859\n",
            "Epoch 4/300\n",
            "32/32 [==============================] - 1s 33ms/step - d_loss: 0.6997 - g_loss: 0.6882\n",
            "Epoch 5/300\n",
            "32/32 [==============================] - 1s 26ms/step - d_loss: 0.6909 - g_loss: 0.6931\n",
            "Epoch 6/300\n",
            "32/32 [==============================] - 1s 25ms/step - d_loss: 0.7005 - g_loss: 0.6912\n",
            "Epoch 7/300\n",
            "32/32 [==============================] - 1s 29ms/step - d_loss: 0.7133 - g_loss: 0.6723\n",
            "Epoch 8/300\n",
            "32/32 [==============================] - 1s 25ms/step - d_loss: 0.7059 - g_loss: 0.6761\n",
            "Epoch 9/300\n",
            "32/32 [==============================] - 1s 25ms/step - d_loss: 0.7036 - g_loss: 0.6829\n",
            "Epoch 10/300\n",
            "32/32 [==============================] - 1s 25ms/step - d_loss: 0.6976 - g_loss: 0.6908\n",
            "Epoch 11/300\n",
            "32/32 [==============================] - 1s 22ms/step - d_loss: 0.6932 - g_loss: 0.6956\n",
            "Epoch 12/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.6938 - g_loss: 0.6936\n",
            "Epoch 13/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6977 - g_loss: 0.6944\n",
            "Epoch 14/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6910 - g_loss: 0.6964\n",
            "Epoch 15/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6943 - g_loss: 0.6922\n",
            "Epoch 16/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6966 - g_loss: 0.6872\n",
            "Epoch 17/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6909 - g_loss: 0.6891\n",
            "Epoch 18/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6927 - g_loss: 0.6872\n",
            "Epoch 19/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6858 - g_loss: 0.6978\n",
            "Epoch 20/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6754 - g_loss: 0.7128\n",
            "Epoch 21/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6701 - g_loss: 0.7167\n",
            "Epoch 22/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6966 - g_loss: 0.6720\n",
            "Epoch 23/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.7132 - g_loss: 0.6531\n",
            "Epoch 24/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.7093 - g_loss: 0.6656\n",
            "Epoch 25/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6955 - g_loss: 0.6849\n",
            "Epoch 26/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6921 - g_loss: 0.6952\n",
            "Epoch 27/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6887 - g_loss: 0.6908\n",
            "Epoch 28/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7011 - g_loss: 0.6640\n",
            "Epoch 29/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7031 - g_loss: 0.6560\n",
            "Epoch 30/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7014 - g_loss: 0.6621\n",
            "Epoch 31/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7108 - g_loss: 0.6563\n",
            "Epoch 32/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7165 - g_loss: 0.6429\n",
            "Epoch 33/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7114 - g_loss: 0.6538\n",
            "Epoch 34/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6988 - g_loss: 0.6678\n",
            "Epoch 35/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6941 - g_loss: 0.6734\n",
            "Epoch 36/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6943 - g_loss: 0.6796\n",
            "Epoch 37/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6928 - g_loss: 0.6884\n",
            "Epoch 38/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6903 - g_loss: 0.6861\n",
            "Epoch 39/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6979 - g_loss: 0.6904\n",
            "Epoch 40/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6971 - g_loss: 0.6913\n",
            "Epoch 41/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6939 - g_loss: 0.7074\n",
            "Epoch 42/300\n",
            "32/32 [==============================] - 1s 21ms/step - d_loss: 0.6821 - g_loss: 0.7170\n",
            "Epoch 43/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6951 - g_loss: 0.7012\n",
            "Epoch 44/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6931 - g_loss: 0.6947\n",
            "Epoch 45/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6978 - g_loss: 0.6809\n",
            "Epoch 46/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.7014 - g_loss: 0.6719\n",
            "Epoch 47/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6911 - g_loss: 0.6800\n",
            "Epoch 48/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.6880 - g_loss: 0.6782\n",
            "Epoch 49/300\n",
            "32/32 [==============================] - 1s 16ms/step - d_loss: 0.6983 - g_loss: 0.6598\n",
            "Epoch 50/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7039 - g_loss: 0.6577\n",
            "Epoch 51/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7020 - g_loss: 0.6616\n",
            "Epoch 52/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6970 - g_loss: 0.6737\n",
            "Epoch 53/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6976 - g_loss: 0.6833\n",
            "Epoch 54/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6874 - g_loss: 0.6944\n",
            "Epoch 55/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6789 - g_loss: 0.7029\n",
            "Epoch 56/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6803 - g_loss: 0.7048\n",
            "Epoch 57/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6882 - g_loss: 0.7021\n",
            "Epoch 58/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6983 - g_loss: 0.6850\n",
            "Epoch 59/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7111 - g_loss: 0.6700\n",
            "Epoch 60/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7078 - g_loss: 0.6787\n",
            "Epoch 61/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7064 - g_loss: 0.6785\n",
            "Epoch 62/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7017 - g_loss: 0.6750\n",
            "Epoch 63/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7048 - g_loss: 0.6580\n",
            "Epoch 64/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7054 - g_loss: 0.6504\n",
            "Epoch 65/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7047 - g_loss: 0.6553\n",
            "Epoch 66/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6977 - g_loss: 0.6656\n",
            "Epoch 67/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6808 - g_loss: 0.6841\n",
            "Epoch 68/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6702 - g_loss: 0.6985\n",
            "Epoch 69/300\n",
            "32/32 [==============================] - 1s 16ms/step - d_loss: 0.6600 - g_loss: 0.7015\n",
            "Epoch 70/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.7078 - g_loss: 0.6229\n",
            "Epoch 71/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.7034 - g_loss: 0.6396\n",
            "Epoch 72/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.7023 - g_loss: 0.6533\n",
            "Epoch 73/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.7035 - g_loss: 0.6675\n",
            "Epoch 74/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.7052 - g_loss: 0.6811\n",
            "Epoch 75/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.6971 - g_loss: 0.6900\n",
            "Epoch 76/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.6946 - g_loss: 0.6994\n",
            "Epoch 77/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6919 - g_loss: 0.7075\n",
            "Epoch 78/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6922 - g_loss: 0.7133\n",
            "Epoch 79/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6844 - g_loss: 0.7214\n",
            "Epoch 80/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6882 - g_loss: 0.7292\n",
            "Epoch 81/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6863 - g_loss: 0.7361\n",
            "Epoch 82/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6808 - g_loss: 0.7432\n",
            "Epoch 83/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6805 - g_loss: 0.7469\n",
            "Epoch 84/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6799 - g_loss: 0.7562\n",
            "Epoch 85/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6803 - g_loss: 0.7665\n",
            "Epoch 86/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6792 - g_loss: 0.7805\n",
            "Epoch 87/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6725 - g_loss: 0.7997\n",
            "Epoch 88/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6679 - g_loss: 0.8116\n",
            "Epoch 89/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6705 - g_loss: 0.8184\n",
            "Epoch 90/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6627 - g_loss: 0.8237\n",
            "Epoch 91/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6592 - g_loss: 0.8372\n",
            "Epoch 92/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6644 - g_loss: 0.8445\n",
            "Epoch 93/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6559 - g_loss: 0.8535\n",
            "Epoch 94/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6535 - g_loss: 0.8635\n",
            "Epoch 95/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6485 - g_loss: 0.8745\n",
            "Epoch 96/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.6474 - g_loss: 0.8822\n",
            "Epoch 97/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6416 - g_loss: 0.8789\n",
            "Epoch 98/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6397 - g_loss: 0.8838\n",
            "Epoch 99/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6375 - g_loss: 0.8905\n",
            "Epoch 100/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.6273 - g_loss: 0.8945\n",
            "Epoch 101/300\n",
            "32/32 [==============================] - 1s 21ms/step - d_loss: 0.6210 - g_loss: 0.8913\n",
            "Epoch 102/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.6201 - g_loss: 0.8955\n",
            "Epoch 103/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6164 - g_loss: 0.9032\n",
            "Epoch 104/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6091 - g_loss: 0.9086\n",
            "Epoch 105/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5987 - g_loss: 0.9136\n",
            "Epoch 106/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5893 - g_loss: 0.9212\n",
            "Epoch 107/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5905 - g_loss: 0.9229\n",
            "Epoch 108/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5809 - g_loss: 0.9312\n",
            "Epoch 109/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5756 - g_loss: 0.9433\n",
            "Epoch 110/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5679 - g_loss: 0.9496\n",
            "Epoch 111/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5569 - g_loss: 0.9675\n",
            "Epoch 112/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5511 - g_loss: 0.9826\n",
            "Epoch 113/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5433 - g_loss: 0.9997\n",
            "Epoch 114/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5348 - g_loss: 0.9974\n",
            "Epoch 115/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5188 - g_loss: 1.0096\n",
            "Epoch 116/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6079 - g_loss: 0.8596\n",
            "Epoch 117/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.9652 - g_loss: 0.3269\n",
            "Epoch 118/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.8948 - g_loss: 0.3281\n",
            "Epoch 119/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.8998 - g_loss: 0.3269\n",
            "Epoch 120/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.8705 - g_loss: 0.3534\n",
            "Epoch 121/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.8705 - g_loss: 0.3646\n",
            "Epoch 122/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.8210 - g_loss: 0.4152\n",
            "Epoch 123/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.7789 - g_loss: 0.4654\n",
            "Epoch 124/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.7699 - g_loss: 0.4846\n",
            "Epoch 125/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.7773 - g_loss: 0.4789\n",
            "Epoch 126/300\n",
            "32/32 [==============================] - 1s 16ms/step - d_loss: 0.7686 - g_loss: 0.5024\n",
            "Epoch 127/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7575 - g_loss: 0.5148\n",
            "Epoch 128/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7539 - g_loss: 0.5213\n",
            "Epoch 129/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7511 - g_loss: 0.5313\n",
            "Epoch 130/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7385 - g_loss: 0.5449\n",
            "Epoch 131/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7296 - g_loss: 0.5646\n",
            "Epoch 132/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7107 - g_loss: 0.5844\n",
            "Epoch 133/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6956 - g_loss: 0.6024\n",
            "Epoch 134/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6925 - g_loss: 0.6054\n",
            "Epoch 135/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6942 - g_loss: 0.5892\n",
            "Epoch 136/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6942 - g_loss: 0.5882\n",
            "Epoch 137/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6891 - g_loss: 0.5893\n",
            "Epoch 138/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6826 - g_loss: 0.5945\n",
            "Epoch 139/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7014 - g_loss: 0.5647\n",
            "Epoch 140/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7143 - g_loss: 0.5620\n",
            "Epoch 141/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7116 - g_loss: 0.5808\n",
            "Epoch 142/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7026 - g_loss: 0.6143\n",
            "Epoch 143/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6884 - g_loss: 0.6506\n",
            "Epoch 144/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6795 - g_loss: 0.6809\n",
            "Epoch 145/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.6835 - g_loss: 0.6742\n",
            "Epoch 146/300\n",
            "32/32 [==============================] - 1s 22ms/step - d_loss: 0.6899 - g_loss: 0.6776\n",
            "Epoch 147/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.6915 - g_loss: 0.6872\n",
            "Epoch 148/300\n",
            "32/32 [==============================] - 1s 25ms/step - d_loss: 0.6937 - g_loss: 0.6897\n",
            "Epoch 149/300\n",
            "32/32 [==============================] - 1s 21ms/step - d_loss: 0.6954 - g_loss: 0.6898\n",
            "Epoch 150/300\n",
            "32/32 [==============================] - 1s 22ms/step - d_loss: 0.6902 - g_loss: 0.6972\n",
            "Epoch 151/300\n",
            "32/32 [==============================] - 1s 23ms/step - d_loss: 0.6744 - g_loss: 0.7075\n",
            "Epoch 152/300\n",
            "32/32 [==============================] - 1s 23ms/step - d_loss: 0.6796 - g_loss: 0.6999\n",
            "Epoch 153/300\n",
            "32/32 [==============================] - 1s 22ms/step - d_loss: 0.6888 - g_loss: 0.6877\n",
            "Epoch 154/300\n",
            "32/32 [==============================] - 1s 22ms/step - d_loss: 0.6887 - g_loss: 0.6985\n",
            "Epoch 155/300\n",
            "32/32 [==============================] - 1s 31ms/step - d_loss: 0.6855 - g_loss: 0.7321\n",
            "Epoch 156/300\n",
            "32/32 [==============================] - 1s 32ms/step - d_loss: 0.6840 - g_loss: 0.7516\n",
            "Epoch 157/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.6936 - g_loss: 0.7274\n",
            "Epoch 158/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7139 - g_loss: 0.6713\n",
            "Epoch 159/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7155 - g_loss: 0.6458\n",
            "Epoch 160/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7010 - g_loss: 0.6453\n",
            "Epoch 161/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6894 - g_loss: 0.6540\n",
            "Epoch 162/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6850 - g_loss: 0.6452\n",
            "Epoch 163/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6905 - g_loss: 0.6380\n",
            "Epoch 164/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6861 - g_loss: 0.6487\n",
            "Epoch 165/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6858 - g_loss: 0.6428\n",
            "Epoch 166/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.7036 - g_loss: 0.6190\n",
            "Epoch 167/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7287 - g_loss: 0.5929\n",
            "Epoch 168/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7149 - g_loss: 0.6249\n",
            "Epoch 169/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.7003 - g_loss: 0.6513\n",
            "Epoch 170/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6918 - g_loss: 0.6729\n",
            "Epoch 171/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6845 - g_loss: 0.6835\n",
            "Epoch 172/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6916 - g_loss: 0.6674\n",
            "Epoch 173/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6935 - g_loss: 0.6881\n",
            "Epoch 174/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.6838 - g_loss: 0.7130\n",
            "Epoch 175/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6803 - g_loss: 0.7340\n",
            "Epoch 176/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6764 - g_loss: 0.7521\n",
            "Epoch 177/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.6781 - g_loss: 0.7626\n",
            "Epoch 178/300\n",
            "32/32 [==============================] - 1s 21ms/step - d_loss: 0.6654 - g_loss: 0.7929\n",
            "Epoch 179/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.6585 - g_loss: 0.8488\n",
            "Epoch 180/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6551 - g_loss: 0.8840\n",
            "Epoch 181/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.6472 - g_loss: 0.9042\n",
            "Epoch 182/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6412 - g_loss: 0.9144\n",
            "Epoch 183/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6407 - g_loss: 0.9227\n",
            "Epoch 184/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6359 - g_loss: 0.9250\n",
            "Epoch 185/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.6315 - g_loss: 0.9308\n",
            "Epoch 186/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.6230 - g_loss: 0.9423\n",
            "Epoch 187/300\n",
            "32/32 [==============================] - 1s 27ms/step - d_loss: 0.6177 - g_loss: 0.9553\n",
            "Epoch 188/300\n",
            "32/32 [==============================] - 1s 30ms/step - d_loss: 0.6077 - g_loss: 0.9668\n",
            "Epoch 189/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.6035 - g_loss: 0.9732\n",
            "Epoch 190/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.6002 - g_loss: 0.9762\n",
            "Epoch 191/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5858 - g_loss: 0.9860\n",
            "Epoch 192/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5746 - g_loss: 1.0011\n",
            "Epoch 193/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.5713 - g_loss: 1.0158\n",
            "Epoch 194/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5638 - g_loss: 1.0180\n",
            "Epoch 195/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.5558 - g_loss: 1.0282\n",
            "Epoch 196/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.5510 - g_loss: 1.0316\n",
            "Epoch 197/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.5415 - g_loss: 1.0428\n",
            "Epoch 198/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.5348 - g_loss: 1.0451\n",
            "Epoch 199/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.5284 - g_loss: 1.0579\n",
            "Epoch 200/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.5128 - g_loss: 1.0646\n",
            "Epoch 201/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.5166 - g_loss: 1.0708\n",
            "Epoch 202/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.5098 - g_loss: 1.0900\n",
            "Epoch 203/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4847 - g_loss: 1.1038\n",
            "Epoch 204/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.4793 - g_loss: 1.1182\n",
            "Epoch 205/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4707 - g_loss: 1.1165\n",
            "Epoch 206/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4607 - g_loss: 1.1194\n",
            "Epoch 207/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.4566 - g_loss: 1.1395\n",
            "Epoch 208/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4406 - g_loss: 1.1583\n",
            "Epoch 209/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4366 - g_loss: 1.1687\n",
            "Epoch 210/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.4232 - g_loss: 1.1966\n",
            "Epoch 211/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4048 - g_loss: 1.2191\n",
            "Epoch 212/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.4071 - g_loss: 1.2481\n",
            "Epoch 213/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3849 - g_loss: 1.2716\n",
            "Epoch 214/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3745 - g_loss: 1.2923\n",
            "Epoch 215/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3702 - g_loss: 1.3185\n",
            "Epoch 216/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3589 - g_loss: 1.3186\n",
            "Epoch 217/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3471 - g_loss: 1.3348\n",
            "Epoch 218/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3428 - g_loss: 1.3547\n",
            "Epoch 219/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.3183 - g_loss: 1.3642\n",
            "Epoch 220/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.3214 - g_loss: 1.3883\n",
            "Epoch 221/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.3010 - g_loss: 1.4009\n",
            "Epoch 222/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.2954 - g_loss: 1.4365\n",
            "Epoch 223/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.2822 - g_loss: 1.4549\n",
            "Epoch 224/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.2757 - g_loss: 1.4672\n",
            "Epoch 225/300\n",
            "32/32 [==============================] - 1s 38ms/step - d_loss: 0.2569 - g_loss: 1.4916\n",
            "Epoch 226/300\n",
            "32/32 [==============================] - 1s 40ms/step - d_loss: 0.2445 - g_loss: 1.5454\n",
            "Epoch 227/300\n",
            "32/32 [==============================] - 1s 16ms/step - d_loss: 0.2299 - g_loss: 1.5522\n",
            "Epoch 228/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.2304 - g_loss: 1.5534\n",
            "Epoch 229/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.2273 - g_loss: 1.5884\n",
            "Epoch 230/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.2121 - g_loss: 1.6362\n",
            "Epoch 231/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.2060 - g_loss: 1.6392\n",
            "Epoch 232/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1840 - g_loss: 1.6621\n",
            "Epoch 233/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.1812 - g_loss: 1.6783\n",
            "Epoch 234/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1765 - g_loss: 1.6987\n",
            "Epoch 235/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.1523 - g_loss: 1.7359\n",
            "Epoch 236/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1540 - g_loss: 1.7919\n",
            "Epoch 237/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.1504 - g_loss: 1.8051\n",
            "Epoch 238/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1373 - g_loss: 1.8225\n",
            "Epoch 239/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.1301 - g_loss: 1.8395\n",
            "Epoch 240/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1095 - g_loss: 1.8863\n",
            "Epoch 241/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1044 - g_loss: 1.8954\n",
            "Epoch 242/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1073 - g_loss: 1.9099\n",
            "Epoch 243/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.1054 - g_loss: 1.9304\n",
            "Epoch 244/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.1003 - g_loss: 1.9441\n",
            "Epoch 245/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.0614 - g_loss: 2.0241\n",
            "Epoch 246/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: 0.0544 - g_loss: 2.0391\n",
            "Epoch 247/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.0630 - g_loss: 2.0561\n",
            "Epoch 248/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: 0.0558 - g_loss: 2.0609\n",
            "Epoch 249/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.0410 - g_loss: 2.0737\n",
            "Epoch 250/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: 0.0396 - g_loss: 2.0973\n",
            "Epoch 251/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: 0.0139 - g_loss: 2.1556\n",
            "Epoch 252/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: 0.0281 - g_loss: 2.1922\n",
            "Epoch 253/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: 0.0142 - g_loss: 2.2039\n",
            "Epoch 254/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: 0.0035 - g_loss: 2.1817\n",
            "Epoch 255/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0024 - g_loss: 2.2661\n",
            "Epoch 256/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0176 - g_loss: 2.2527\n",
            "Epoch 257/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0124 - g_loss: 2.2521\n",
            "Epoch 258/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0261 - g_loss: 2.3314\n",
            "Epoch 259/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0418 - g_loss: 2.3612\n",
            "Epoch 260/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0434 - g_loss: 2.4031\n",
            "Epoch 261/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0502 - g_loss: 2.4354\n",
            "Epoch 262/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0670 - g_loss: 2.4583\n",
            "Epoch 263/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0701 - g_loss: 2.4695\n",
            "Epoch 264/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0715 - g_loss: 2.4787\n",
            "Epoch 265/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0754 - g_loss: 2.5122\n",
            "Epoch 266/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.0865 - g_loss: 2.6285\n",
            "Epoch 267/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.0922 - g_loss: 2.6165\n",
            "Epoch 268/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.1010 - g_loss: 2.6160\n",
            "Epoch 269/300\n",
            "32/32 [==============================] - 1s 17ms/step - d_loss: -0.1175 - g_loss: 2.6336\n",
            "Epoch 270/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.1191 - g_loss: 2.6565\n",
            "Epoch 271/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.1221 - g_loss: 2.7442\n",
            "Epoch 272/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.1134 - g_loss: 2.7171\n",
            "Epoch 273/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.1395 - g_loss: 2.7513\n",
            "Epoch 274/300\n",
            "32/32 [==============================] - 1s 20ms/step - d_loss: -0.1618 - g_loss: 2.7537\n",
            "Epoch 275/300\n",
            "32/32 [==============================] - 0s 15ms/step - d_loss: -0.1528 - g_loss: 2.8339\n",
            "Epoch 276/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.1674 - g_loss: 2.8974\n",
            "Epoch 277/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.1465 - g_loss: 2.8477\n",
            "Epoch 278/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.1926 - g_loss: 2.8530\n",
            "Epoch 279/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.1758 - g_loss: 2.8874\n",
            "Epoch 280/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.1808 - g_loss: 2.8912\n",
            "Epoch 281/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2124 - g_loss: 3.0027\n",
            "Epoch 282/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.2150 - g_loss: 3.0449\n",
            "Epoch 283/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2261 - g_loss: 3.0675\n",
            "Epoch 284/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2189 - g_loss: 3.0938\n",
            "Epoch 285/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.2329 - g_loss: 3.1304\n",
            "Epoch 286/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2393 - g_loss: 3.1827\n",
            "Epoch 287/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2586 - g_loss: 3.1525\n",
            "Epoch 288/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.2586 - g_loss: 3.2166\n",
            "Epoch 289/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2869 - g_loss: 3.2132\n",
            "Epoch 290/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.2769 - g_loss: 3.2949\n",
            "Epoch 291/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.2926 - g_loss: 3.2818\n",
            "Epoch 292/300\n",
            "32/32 [==============================] - 0s 13ms/step - d_loss: -0.2943 - g_loss: 3.3329\n",
            "Epoch 293/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: -0.2848 - g_loss: 3.4024\n",
            "Epoch 294/300\n",
            "32/32 [==============================] - 1s 16ms/step - d_loss: -0.3012 - g_loss: 3.3335\n",
            "Epoch 295/300\n",
            "32/32 [==============================] - 1s 19ms/step - d_loss: -0.3188 - g_loss: 3.4789\n",
            "Epoch 296/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.3343 - g_loss: 3.5426\n",
            "Epoch 297/300\n",
            "32/32 [==============================] - 1s 18ms/step - d_loss: -0.3403 - g_loss: 3.5719\n",
            "Epoch 298/300\n",
            "32/32 [==============================] - 1s 21ms/step - d_loss: -0.3619 - g_loss: 3.6470\n",
            "Epoch 299/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.3420 - g_loss: 3.7207\n",
            "Epoch 300/300\n",
            "32/32 [==============================] - 0s 14ms/step - d_loss: -0.3662 - g_loss: 3.7545\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7abda716f4f0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gan = GAN(d_model, g_model, latent_dim=128)\n",
        "\n",
        "gan.compile(\n",
        "    d_optimizer = d_opt,\n",
        "    g_optimizer = g_opt,\n",
        "    loss_fn = loss_function,\n",
        "    )\n",
        "\n",
        "gan.fit(dataset, epochs = 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q_Arh-_DbJD"
      },
      "outputs": [],
      "source": [
        "batch_size=8\n",
        "random_latent_vectors = tf.random.normal(shape=(batch_size, 128))\n",
        "generated_images = g_model(random_latent_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "g-QVuDBZDsyL",
        "outputId": "ddbb25b6-6140-414e-e719-1c8cff6350ed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size=8\n",
        "random_latent_vectors = tf.random.normal(shape=(batch_size, 128))\n",
        "generated_images = g_model(random_latent_vectors)\n",
        "#generated_images = tf.where(generated_images >= 0.5, tf.ones_like(generated_images), tf.zeros_like(generated_images))\n",
        "# Assuming you have a list of 8 generated images named `generated_images`\n",
        "num_samples = len(generated_images)\n",
        "\n",
        "# Create subplot grid\n",
        "num_rows = 2\n",
        "num_cols = 4\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(6, 3))\n",
        "\n",
        "# Display generated images\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    if i < num_samples:\n",
        "        ax.imshow(generated_images[i], cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "dCPUz-UFqX7y",
        "outputId": "d6aa4051-74f3-4193-9c1e-2f1dbf0b20d8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer count mismatch when loading weights from file. Model expected 0 layers, found 2 saved layers.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d8c65206d752>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;34m\"Layer count mismatch when loading weights from file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;34mf\"Model expected {len(filtered_layers)} layers, found \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 0 layers, found 2 saved layers."
          ]
        }
      ],
      "source": [
        "model.build(input_shape=(16, 128,1))\n",
        "\n",
        "model.load_weights(path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "xBnFU2kvq2mX",
        "outputId": "19eddd71-08ca-415c-8366-1c8a5cf55a11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78721e60c1f0>"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size=8\n",
        "random_latent_vectors = tf.random.normal(shape=(batch_size, 128))\n",
        "generated_images = g_model(random_latent_vectors)\n",
        "generated_images = tf.where(generated_images >= 0.5, tf.ones_like(generated_images), tf.zeros_like(generated_images))\n",
        "\n",
        "# Assuming you have a list of 8 generated images named `generated_images`\n",
        "num_samples = len(generated_images)\n",
        "\n",
        "# Create subplot grid\n",
        "plt.imshow(generated_images[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhKuROy7GOG9",
        "outputId": "4998bd98-aa2a-417d-a011-b30671f7a0bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 1), dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_images[0][14]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tz1ojCENoQa"
      },
      "source": [
        "# 2 Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lDF7aF0NrlL",
        "outputId": "57978483-98b7-4a2a-a20b-bef2b6f028ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15, 15)\n",
            "500\n"
          ]
        }
      ],
      "source": [
        "train_images = []\n",
        "\n",
        "for i in range (1,501):\n",
        "  img = cv2.imread(f'Dataset_1st/img_{i}.png')\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  img = img[129:251, 129:251]\n",
        "  ret, img = cv2.threshold(img, 245, 255, cv2.THRESH_BINARY)\n",
        "  img = img.astype(\"float32\") / 255.0\n",
        "  img = cv2.resize(img, (15,15))\n",
        "  #img = cv2.resize(img, (28,28))\n",
        "  #img = tf.expand_dims(img, axis=-1)\n",
        "  train_images.append(img)\n",
        "\n",
        "print(train_images[2].shape)\n",
        "print(len(train_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "OfY_vvC3IvWy",
        "outputId": "42f6900d-c1b1-4f76-a9ab-96fac8c0e7bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7981f1342560>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "a = np.zeros((15,15,3))\n",
        "J=[]\n",
        "\n",
        "for i in range(250):\n",
        "  a = np.zeros((15,15,3))\n",
        "  a[:,:,0] = train_images[2*i]\n",
        "  a[:,:,1] = train_images[2*i+1]\n",
        "  a[:,:,2] = a[:,:,0]\n",
        "  J.append(a)\n",
        "\n",
        "J[1][:,:,0]\n",
        "plt.imshow(J[1][:,:,2], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpee9A16Iwto",
        "outputId": "711f1edb-43fc-4c90-8779-cb66b8fa2e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 15, 15, 3)\n"
          ]
        }
      ],
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices(J)\n",
        "ds = ds.batch(16)\n",
        "ds = ds.shuffle(50)\n",
        "j=[]\n",
        "for element in ds:\n",
        "  j.append(element)\n",
        "\n",
        "print(j[10].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy1HZn24OQAn"
      },
      "outputs": [],
      "source": [
        "# Discriminator model\n",
        "d_model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 28x28x1 into 14x14x32 tensor\n",
        "d_model.add(Conv2D(32,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=(15,15,1),\n",
        "               padding='same'))\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "d_model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 14x14x32 into 7x7x64 tensor\n",
        "d_model.add(Conv2D(64,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "d_model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "d_model.add(Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "d_model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "d_model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "d_model.add(Flatten())\n",
        "d_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "g_model = Sequential()\n",
        "\n",
        "  # Reshape input into 7x7x256 tensor via a fully connected layer\n",
        "g_model.add(Dense(256 * 7 * 7, input_dim=latent_dim))\n",
        "g_model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "    # Transposed convolution layer, from 7x7x256 into 14x14x128 tensor\n",
        "g_model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='valid'))\n",
        "\n",
        "    # Batch normalization\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "g_model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
        "g_model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "g_model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "g_model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "g_model.add(Conv2DTranspose(1, kernel_size=3, strides=1, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "g_model.add(Activation('tanh'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0IPoD7hmbxQo",
        "oewo3krpxHDS",
        "tYhcnnzCi4RV",
        "1Tz1ojCENoQa"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOBQ/Drom/pK+M13aM+BXrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}